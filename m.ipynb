{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c25dee1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "✓ TensorFlow detected GPU: /physical_device:GPU:0\n",
      "============================================================\n",
      "\n",
      "MODE: LIVE | SCENARIO: CROWD | Using Detector: retinaface\n",
      "Starting real-time stream...\n",
      "\n",
      "✓ Stream stopped.\n",
      "\n",
      "============================================================\n",
      "SCRIPT FINISHED.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# ADVANCED FACE RECOGNITION SYSTEM (LOCAL PC VERSION) - FINAL\n",
    "# This version has fully functional IMAGE, VIDEO, and LIVE modes.\n",
    "# ====================================================================\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Suppress TensorFlow warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "\n",
    "# ====================================================================\n",
    "# MASTER CONFIGURATION\n",
    "# ====================================================================\n",
    "MODE = 'LIVE' # Options: 'IMAGE', 'VIDEO', 'LIVE'\n",
    "\n",
    "# --- Scenario Configuration ---\n",
    "# 'INDIVIDUAL': Performs face recognition.\n",
    "# 'CROWD': Performs only face detection.\n",
    "SCENARIO = 'CROWD'\n",
    "\n",
    "# --- Paths and Settings ---\n",
    "LOCAL_PROJECT_FOLDER = 'C:/Users/mswuk/OneDrive/Desktop/NEURALNERWORK/Dataset'\n",
    "INPUT_FILENAME = 'test2.jpg' # Used for IMAGE/VIDEO modes\n",
    "CAM_ID = 0 # Used for LIVE mode\n",
    "DATABASE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, \"database\")\n",
    "CAPTURE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, \"captures\")\n",
    "\n",
    "# --- Detector & Recognition Configuration ---\n",
    "DETECTOR_FOR_CROWD = 'retinaface'\n",
    "DETECTOR_FOR_INDIVIDUAL = 'retinaface'\n",
    "RECOGNITION_MODEL = 'VGG-Face'\n",
    "DISTANCE_METRIC = 'cosine'\n",
    "RECOGNITION_THRESHOLD = 0.65 # Lower is stricter (0.0 to 1.0)\n",
    "# -----------------------------\n",
    "\n",
    "\n",
    "# --- SCRIPT SETUP ---\n",
    "INPUT_FILE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, INPUT_FILENAME)\n",
    "\n",
    "for path in [DATABASE_PATH, CAPTURE_PATH]:\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"INFO: Folder not found. Creating one at: {path}\")\n",
    "        os.makedirs(path)\n",
    "\n",
    "print(\"=\"*60)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"✓ TensorFlow detected GPU: {gpus[0].name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"GPU setup error: {e}\")\n",
    "else:\n",
    "    print(\"✗ WARNING: TensorFlow DID NOT detect a GPU!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# --- OPTIMIZATION: PRE-LOAD AND PRE-PROCESS THE DATABASE ---\n",
    "# ======================================================================================\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "if SCENARIO == 'INDIVIDUAL':\n",
    "    print(\"Pre-loading and processing face database for recognition...\")\n",
    "    db_images = [f for f in os.listdir(DATABASE_PATH) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    if not db_images:\n",
    "        print(\"WARNING: 'database' folder is empty. Recognition will not find any matches.\")\n",
    "    else:\n",
    "        for filename in db_images:\n",
    "            filepath = os.path.join(DATABASE_PATH, filename)\n",
    "            try:\n",
    "                embedding_obj = DeepFace.represent(img_path=filepath, model_name=RECOGNITION_MODEL, enforce_detection=False)\n",
    "                if embedding_obj and 'embedding' in embedding_obj[0]:\n",
    "                    known_face_encodings.append(embedding_obj[0]['embedding'])\n",
    "                    name = os.path.splitext(filename)[0].replace(\"_\", \" \")\n",
    "                    known_face_names.append(name)\n",
    "                    print(f\"  ✓ Processed: {name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ Could not process {filename}: {e}\")\n",
    "    print(f\"✓ Database loaded. Found {len(known_face_names)} known faces.\")\n",
    "\n",
    "# --- Helper function for fast recognition ---\n",
    "def find_best_match(target_embedding, known_embeddings, known_names, threshold):\n",
    "    if not known_embeddings: return None\n",
    "    distances = []\n",
    "    for known_embedding in known_embeddings:\n",
    "        distance = 1 - np.dot(target_embedding, known_embedding) / (np.linalg.norm(target_embedding) * np.linalg.norm(known_embedding))\n",
    "        distances.append(distance)\n",
    "    if distances:\n",
    "        min_idx = np.argmin(distances)\n",
    "        if distances[min_idx] <= threshold:\n",
    "            return known_names[min_idx]\n",
    "    return None\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# --- MAIN LOGIC ---\n",
    "# ======================================================================================\n",
    "\n",
    "if MODE == 'IMAGE':\n",
    "    detector_backend = DETECTOR_FOR_CROWD if SCENARIO == 'CROWD' else DETECTOR_FOR_INDIVIDUAL\n",
    "    print(f\"\\nMODE: IMAGE | SCENARIO: {SCENARIO} | Using Detector: {detector_backend}\")\n",
    "    print(f\"Processing file: {INPUT_FILENAME}\")\n",
    "    \n",
    "    if not os.path.exists(INPUT_FILE_PATH):\n",
    "        print(f\"❌ Error: Image file not found at {INPUT_FILE_PATH}\")\n",
    "    else:\n",
    "        try:\n",
    "            img = cv2.imread(INPUT_FILE_PATH)\n",
    "            \n",
    "            faces = DeepFace.extract_faces(\n",
    "                img_path=img, detector_backend=detector_backend,\n",
    "                enforce_detection=False, align=False\n",
    "            )\n",
    "            num_faces = len(faces)\n",
    "            print(f\"✓ Found {num_faces} faces.\")\n",
    "\n",
    "            if SCENARIO == 'INDIVIDUAL' and num_faces > 0:\n",
    "                print(f\"-> Performing face recognition...\")\n",
    "                for face in faces:\n",
    "                    fa = face['facial_area']\n",
    "                    x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']\n",
    "                    \n",
    "                    face_embedding_obj = DeepFace.represent(img_path=img[y:y+h, x:x+w], model_name=RECOGNITION_MODEL, enforce_detection=False)\n",
    "                    if face_embedding_obj and 'embedding' in face_embedding_obj[0]:\n",
    "                        identity = find_best_match(face_embedding_obj[0]['embedding'], known_face_encodings, known_face_names, RECOGNITION_THRESHOLD)\n",
    "                        \n",
    "                        if identity:\n",
    "                            color, name_to_display = (0, 255, 0), identity\n",
    "                        else:\n",
    "                            color, name_to_display = (0, 0, 255), \"Unknown\"\n",
    "                            \n",
    "                        cv2.rectangle(img, (x, y), (x + w, y + h), color, 1)\n",
    "                        cv2.putText(img, name_to_display, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 1)\n",
    "            else: # CROWD mode\n",
    "                for face in faces:\n",
    "                    fa = face['facial_area']\n",
    "                    x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']\n",
    "                    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 165, 0), 1)\n",
    "\n",
    "            output_filename = 'output_' + INPUT_FILENAME\n",
    "            OUTPUT_FILE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, output_filename)\n",
    "            cv2.imwrite(OUTPUT_FILE_PATH, img)\n",
    "\n",
    "            print(f\"✓ Output image saved to: {OUTPUT_FILE_PATH}\")\n",
    "            print(\"\\nDisplaying result. Press any key to close.\")\n",
    "            cv2.imshow('Image Result', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during image processing: {e}\")\n",
    "\n",
    "elif MODE == 'VIDEO':\n",
    "    detector_backend = DETECTOR_FOR_CROWD if SCENARIO == 'CROWD' else DETECTOR_FOR_INDIVIDUAL\n",
    "    print(f\"\\nMODE: VIDEO | SCENARIO: {SCENARIO} | Using Detector: {detector_backend}\")\n",
    "    print(f\"Processing file: {INPUT_FILENAME}\")\n",
    "\n",
    "    if not os.path.exists(INPUT_FILE_PATH):\n",
    "        print(f\"❌ Error: Video file not found at {INPUT_FILE_PATH}\")\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(INPUT_FILE_PATH)\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        output_filename = 'output_' + os.path.splitext(INPUT_FILENAME)[0] + '.mp4'\n",
    "        OUTPUT_FILE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, output_filename)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(OUTPUT_FILE_PATH, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "        print(f\"✓ Input video loaded. Starting processing... ({total_frames} frames)\")\n",
    "        frame_number = 0\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            frame_number += 1\n",
    "            \n",
    "            try:\n",
    "                faces = DeepFace.extract_faces(\n",
    "                    img_path=frame, detector_backend=detector_backend, enforce_detection=False, align=False\n",
    "                )\n",
    "                \n",
    "                if SCENARIO == 'INDIVIDUAL' and len(faces) > 0:\n",
    "                    for face in faces:\n",
    "                        fa = face['facial_area']\n",
    "                        x,y,w,h = fa['x'],fa['y'],fa['w'],fa['h']\n",
    "                        face_embedding_obj = DeepFace.represent(img_path=frame[y:y+h, x:x+w], model_name=RECOGNITION_MODEL, enforce_detection=False)\n",
    "                        if face_embedding_obj and 'embedding' in face_embedding_obj[0]:\n",
    "                            identity = find_best_match(face_embedding_obj[0]['embedding'], known_face_encodings, known_face_names, RECOGNITION_THRESHOLD)\n",
    "                            color = (0, 255, 0) if identity else (0, 0, 255)\n",
    "                            name = identity if identity else \"Unknown\"\n",
    "                            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 1)\n",
    "                            cv2.putText(frame, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 1)\n",
    "                else: # CROWD\n",
    "                    for face in faces:\n",
    "                        fa = face['facial_area']\n",
    "                        x,y,w,h = fa['x'],fa['y'],fa['w'],fa['h']\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 165, 0), 1)\n",
    "\n",
    "                out.write(frame)\n",
    "                if frame_number % 20 == 0:\n",
    "                    print(f\"  Processed frame {frame_number}/{total_frames}...\")\n",
    "            except Exception as e:\n",
    "                out.write(frame)\n",
    "        \n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"\\n✓ PROCESSING COMPLETE!\")\n",
    "        print(f\"✓ Output video saved to: {OUTPUT_FILE_PATH}\")\n",
    "\n",
    "elif MODE == 'LIVE':\n",
    "    detector_backend = DETECTOR_FOR_CROWD if SCENARIO == 'CROWD' else DETECTOR_FOR_INDIVIDUAL\n",
    "    \n",
    "    print(f\"\\nMODE: LIVE | SCENARIO: {SCENARIO} | Using Detector: {detector_backend}\")\n",
    "    print(\"Starting real-time stream...\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(CAM_ID)\n",
    "    if not cap.isOpened():\n",
    "        raise SystemExit(f\"❌ Camera failed to open at ID {CAM_ID}.\")\n",
    "\n",
    "    WINDOW_NAME = \"Live Face Recognition (Press 'q' to quit)\"\n",
    "    cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
    "    \n",
    "    last_time = time.time()\n",
    "    frames, fps, num_faces = 0, 0, 0\n",
    "    capture_and_stop = False\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "\n",
    "        try:\n",
    "            faces = DeepFace.extract_faces(\n",
    "                img_path=frame, detector_backend=detector_backend, enforce_detection=False, align=False\n",
    "            )\n",
    "            num_faces = len(faces)\n",
    "\n",
    "            if SCENARIO == 'INDIVIDUAL' and num_faces > 0:\n",
    "                for face in faces:\n",
    "                    fa = face['facial_area']\n",
    "                    x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']\n",
    "                    \n",
    "                    face_embedding_obj = DeepFace.represent(img_path=frame[y:y+h, x:x+w], model_name=RECOGNITION_MODEL, enforce_detection=False)\n",
    "                    \n",
    "                    if face_embedding_obj and 'embedding' in face_embedding_obj[0]:\n",
    "                        identity = find_best_match(face_embedding_obj[0]['embedding'], known_face_encodings, known_face_names, RECOGNITION_THRESHOLD)\n",
    "                        \n",
    "                        if identity:\n",
    "                            color, name_to_display = (0, 255, 0), identity\n",
    "                            \n",
    "                            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 1)\n",
    "                            cv2.putText(frame, name_to_display, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 1)\n",
    "\n",
    "                            if not capture_and_stop:\n",
    "                                timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                                capture_filename = f\"capture_{identity.replace(' ', '_')}_{timestamp}.jpg\"\n",
    "                                capture_filepath = os.path.join(CAPTURE_PATH, capture_filename)\n",
    "                                cv2.imwrite(capture_filepath, frame)\n",
    "                                print(f\"\\n✓ Recognized and Captured: {identity} -> {capture_filename}\")\n",
    "                                capture_and_stop = True\n",
    "                        else:\n",
    "                            color, name_to_display = (0, 0, 255), \"Unknown\"\n",
    "                            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 1)\n",
    "                            cv2.putText(frame, name_to_display, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 1)\n",
    "\n",
    "            else: # CROWD mode\n",
    "                 for face in faces:\n",
    "                    fa = face['facial_area']\n",
    "                    x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 165, 0), 1)\n",
    "        except Exception as e:\n",
    "            num_faces = 0\n",
    "        \n",
    "        frames += 1; now = time.time()\n",
    "        if now - last_time >= 1.0:\n",
    "            fps = frames / (now - last_time); frames, last_time = 0, now\n",
    "        \n",
    "        info_text = f\"FPS: {fps:.1f} | Faces: {num_faces} | Mode: {SCENARIO}\"\n",
    "        cv2.putText(frame, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        cv2.imshow(WINDOW_NAME, frame)\n",
    "\n",
    "        if capture_and_stop:\n",
    "            print(\"   Auto-stopping stream...\")\n",
    "            time.sleep(2)\n",
    "            break\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "    cap.release(); cv2.destroyAllWindows()\n",
    "    print(\"\\n✓ Stream stopped.\")\n",
    "\n",
    "else:\n",
    "    print(f\"❌ Error: Invalid MODE selected.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\nSCRIPT FINISHED.\\n\" + \"=\"*60)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
