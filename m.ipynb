<<<<<<< HEAD
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c25dee1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "✓ TensorFlow detected GPU: /physical_device:GPU:0\n",
      "============================================================\n",
      "\n",
      "MODE: LIVE | SCENARIO: CROWD | Using Detector: retinaface\n",
      "Starting real-time stream...\n",
      "\n",
      "✓ Stream stopped.\n",
      "\n",
      "============================================================\n",
      "SCRIPT FINISHED.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# ADVANCED FACE RECOGNITION SYSTEM (LOCAL PC VERSION) - FINAL\n",
    "# This version has fully functional IMAGE, VIDEO, and LIVE modes.\n",
    "# ====================================================================\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Suppress TensorFlow warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "\n",
    "# ====================================================================\n",
    "# MASTER CONFIGURATION\n",
    "# ====================================================================\n",
    "MODE = 'LIVE' # Options: 'IMAGE', 'VIDEO', 'LIVE'\n",
    "\n",
    "# --- Scenario Configuration ---\n",
    "# 'INDIVIDUAL': Performs face recognition.\n",
    "# 'CROWD': Performs only face detection.\n",
    "SCENARIO = 'CROWD'\n",
    "\n",
    "# --- Paths and Settings ---\n",
    "LOCAL_PROJECT_FOLDER = 'C:/Users/mswuk/OneDrive/Desktop/NEURALNERWORK/Dataset'\n",
    "INPUT_FILENAME = 'test2.jpg' # Used for IMAGE/VIDEO modes\n",
    "CAM_ID = 0 # Used for LIVE mode\n",
    "DATABASE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, \"database\")\n",
    "CAPTURE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, \"captures\")\n",
    "\n",
    "# --- Detector & Recognition Configuration ---\n",
    "DETECTOR_FOR_CROWD = 'retinaface'\n",
    "DETECTOR_FOR_INDIVIDUAL = 'retinaface'\n",
    "RECOGNITION_MODEL = 'VGG-Face'\n",
    "DISTANCE_METRIC = 'cosine'\n",
    "RECOGNITION_THRESHOLD = 0.65 # Lower is stricter (0.0 to 1.0)\n",
    "# -----------------------------\n",
    "\n",
    "\n",
    "# --- SCRIPT SETUP ---\n",
    "INPUT_FILE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, INPUT_FILENAME)\n",
    "\n",
    "for path in [DATABASE_PATH, CAPTURE_PATH]:\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"INFO: Folder not found. Creating one at: {path}\")\n",
    "        os.makedirs(path)\n",
    "\n",
    "print(\"=\"*60)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"✓ TensorFlow detected GPU: {gpus[0].name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"GPU setup error: {e}\")\n",
    "else:\n",
    "    print(\"✗ WARNING: TensorFlow DID NOT detect a GPU!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# --- OPTIMIZATION: PRE-LOAD AND PRE-PROCESS THE DATABASE ---\n",
    "# ======================================================================================\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "if SCENARIO == 'INDIVIDUAL':\n",
    "    print(\"Pre-loading and processing face database for recognition...\")\n",
    "    db_images = [f for f in os.listdir(DATABASE_PATH) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    if not db_images:\n",
    "        print(\"WARNING: 'database' folder is empty. Recognition will not find any matches.\")\n",
    "    else:\n",
    "        for filename in db_images:\n",
    "            filepath = os.path.join(DATABASE_PATH, filename)\n",
    "            try:\n",
    "                embedding_obj = DeepFace.represent(img_path=filepath, model_name=RECOGNITION_MODEL, enforce_detection=False)\n",
    "                if embedding_obj and 'embedding' in embedding_obj[0]:\n",
    "                    known_face_encodings.append(embedding_obj[0]['embedding'])\n",
    "                    name = os.path.splitext(filename)[0].replace(\"_\", \" \")\n",
    "                    known_face_names.append(name)\n",
    "                    print(f\"  ✓ Processed: {name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ Could not process {filename}: {e}\")\n",
    "    print(f\"✓ Database loaded. Found {len(known_face_names)} known faces.\")\n",
    "\n",
    "# --- Helper function for fast recognition ---\n",
    "def find_best_match(target_embedding, known_embeddings, known_names, threshold):\n",
    "    if not known_embeddings: return None\n",
    "    distances = []\n",
    "    for known_embedding in known_embeddings:\n",
    "        distance = 1 - np.dot(target_embedding, known_embedding) / (np.linalg.norm(target_embedding) * np.linalg.norm(known_embedding))\n",
    "        distances.append(distance)\n",
    "    if distances:\n",
    "        min_idx = np.argmin(distances)\n",
    "        if distances[min_idx] <= threshold:\n",
    "            return known_names[min_idx]\n",
    "    return None\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# --- MAIN LOGIC ---\n",
    "# ======================================================================================\n",
    "\n",
    "if MODE == 'IMAGE':\n",
    "    detector_backend = DETECTOR_FOR_CROWD if SCENARIO == 'CROWD' else DETECTOR_FOR_INDIVIDUAL\n",
    "    print(f\"\\nMODE: IMAGE | SCENARIO: {SCENARIO} | Using Detector: {detector_backend}\")\n",
    "    print(f\"Processing file: {INPUT_FILENAME}\")\n",
    "    \n",
    "    if not os.path.exists(INPUT_FILE_PATH):\n",
    "        print(f\"❌ Error: Image file not found at {INPUT_FILE_PATH}\")\n",
    "    else:\n",
    "        try:\n",
    "            img = cv2.imread(INPUT_FILE_PATH)\n",
    "            \n",
    "            faces = DeepFace.extract_faces(\n",
    "                img_path=img, detector_backend=detector_backend,\n",
    "                enforce_detection=False, align=False\n",
    "            )\n",
    "            num_faces = len(faces)\n",
    "            print(f\"✓ Found {num_faces} faces.\")\n",
    "\n",
    "            if SCENARIO == 'INDIVIDUAL' and num_faces > 0:\n",
    "                print(f\"-> Performing face recognition...\")\n",
    "                for face in faces:\n",
    "                    fa = face['facial_area']\n",
    "                    x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']\n",
    "                    \n",
    "                    face_embedding_obj = DeepFace.represent(img_path=img[y:y+h, x:x+w], model_name=RECOGNITION_MODEL, enforce_detection=False)\n",
    "                    if face_embedding_obj and 'embedding' in face_embedding_obj[0]:\n",
    "                        identity = find_best_match(face_embedding_obj[0]['embedding'], known_face_encodings, known_face_names, RECOGNITION_THRESHOLD)\n",
    "                        \n",
    "                        if identity:\n",
    "                            color, name_to_display = (0, 255, 0), identity\n",
    "                        else:\n",
    "                            color, name_to_display = (0, 0, 255), \"Unknown\"\n",
    "                            \n",
    "                        cv2.rectangle(img, (x, y), (x + w, y + h), color, 1)\n",
    "                        cv2.putText(img, name_to_display, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 1)\n",
    "            else: # CROWD mode\n",
    "                for face in faces:\n",
    "                    fa = face['facial_area']\n",
    "                    x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']\n",
    "                    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 165, 0), 1)\n",
    "\n",
    "            output_filename = 'output_' + INPUT_FILENAME\n",
    "            OUTPUT_FILE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, output_filename)\n",
    "            cv2.imwrite(OUTPUT_FILE_PATH, img)\n",
    "\n",
    "            print(f\"✓ Output image saved to: {OUTPUT_FILE_PATH}\")\n",
    "            print(\"\\nDisplaying result. Press any key to close.\")\n",
    "            cv2.imshow('Image Result', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during image processing: {e}\")\n",
    "\n",
    "elif MODE == 'VIDEO':\n",
    "    detector_backend = DETECTOR_FOR_CROWD if SCENARIO == 'CROWD' else DETECTOR_FOR_INDIVIDUAL\n",
    "    print(f\"\\nMODE: VIDEO | SCENARIO: {SCENARIO} | Using Detector: {detector_backend}\")\n",
    "    print(f\"Processing file: {INPUT_FILENAME}\")\n",
    "\n",
    "    if not os.path.exists(INPUT_FILE_PATH):\n",
    "        print(f\"❌ Error: Video file not found at {INPUT_FILE_PATH}\")\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(INPUT_FILE_PATH)\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        output_filename = 'output_' + os.path.splitext(INPUT_FILENAME)[0] + '.mp4'\n",
    "        OUTPUT_FILE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, output_filename)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(OUTPUT_FILE_PATH, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "        print(f\"✓ Input video loaded. Starting processing... ({total_frames} frames)\")\n",
    "        frame_number = 0\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            frame_number += 1\n",
    "            \n",
    "            try:\n",
    "                faces = DeepFace.extract_faces(\n",
    "                    img_path=frame, detector_backend=detector_backend, enforce_detection=False, align=False\n",
    "                )\n",
    "                \n",
    "                if SCENARIO == 'INDIVIDUAL' and len(faces) > 0:\n",
    "                    for face in faces:\n",
    "                        fa = face['facial_area']\n",
    "                        x,y,w,h = fa['x'],fa['y'],fa['w'],fa['h']\n",
    "                        face_embedding_obj = DeepFace.represent(img_path=frame[y:y+h, x:x+w], model_name=RECOGNITION_MODEL, enforce_detection=False)\n",
    "                        if face_embedding_obj and 'embedding' in face_embedding_obj[0]:\n",
    "                            identity = find_best_match(face_embedding_obj[0]['embedding'], known_face_encodings, known_face_names, RECOGNITION_THRESHOLD)\n",
    "                            color = (0, 255, 0) if identity else (0, 0, 255)\n",
    "                            name = identity if identity else \"Unknown\"\n",
    "                            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 1)\n",
    "                            cv2.putText(frame, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 1)\n",
    "                else: # CROWD\n",
    "                    for face in faces:\n",
    "                        fa = face['facial_area']\n",
    "                        x,y,w,h = fa['x'],fa['y'],fa['w'],fa['h']\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 165, 0), 1)\n",
    "\n",
    "                out.write(frame)\n",
    "                if frame_number % 20 == 0:\n",
    "                    print(f\"  Processed frame {frame_number}/{total_frames}...\")\n",
    "            except Exception as e:\n",
    "                out.write(frame)\n",
    "        \n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"\\n✓ PROCESSING COMPLETE!\")\n",
    "        print(f\"✓ Output video saved to: {OUTPUT_FILE_PATH}\")\n",
    "\n",
    "elif MODE == 'LIVE':\n",
    "    detector_backend = DETECTOR_FOR_CROWD if SCENARIO == 'CROWD' else DETECTOR_FOR_INDIVIDUAL\n",
    "    \n",
    "    print(f\"\\nMODE: LIVE | SCENARIO: {SCENARIO} | Using Detector: {detector_backend}\")\n",
    "    print(\"Starting real-time stream...\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(CAM_ID)\n",
    "    if not cap.isOpened():\n",
    "        raise SystemExit(f\"❌ Camera failed to open at ID {CAM_ID}.\")\n",
    "\n",
    "    WINDOW_NAME = \"Live Face Recognition (Press 'q' to quit)\"\n",
    "    cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
    "    \n",
    "    last_time = time.time()\n",
    "    frames, fps, num_faces = 0, 0, 0\n",
    "    capture_and_stop = False\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "\n",
    "        try:\n",
    "            faces = DeepFace.extract_faces(\n",
    "                img_path=frame, detector_backend=detector_backend, enforce_detection=False, align=False\n",
    "            )\n",
    "            num_faces = len(faces)\n",
    "\n",
    "            if SCENARIO == 'INDIVIDUAL' and num_faces > 0:\n",
    "                for face in faces:\n",
    "                    fa = face['facial_area']\n",
    "                    x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']\n",
    "                    \n",
    "                    face_embedding_obj = DeepFace.represent(img_path=frame[y:y+h, x:x+w], model_name=RECOGNITION_MODEL, enforce_detection=False)\n",
    "                    \n",
    "                    if face_embedding_obj and 'embedding' in face_embedding_obj[0]:\n",
    "                        identity = find_best_match(face_embedding_obj[0]['embedding'], known_face_encodings, known_face_names, RECOGNITION_THRESHOLD)\n",
    "                        \n",
    "                        if identity:\n",
    "                            color, name_to_display = (0, 255, 0), identity\n",
    "                            \n",
    "                            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 1)\n",
    "                            cv2.putText(frame, name_to_display, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 1)\n",
    "\n",
    "                            if not capture_and_stop:\n",
    "                                timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                                capture_filename = f\"capture_{identity.replace(' ', '_')}_{timestamp}.jpg\"\n",
    "                                capture_filepath = os.path.join(CAPTURE_PATH, capture_filename)\n",
    "                                cv2.imwrite(capture_filepath, frame)\n",
    "                                print(f\"\\n✓ Recognized and Captured: {identity} -> {capture_filename}\")\n",
    "                                capture_and_stop = True\n",
    "                        else:\n",
    "                            color, name_to_display = (0, 0, 255), \"Unknown\"\n",
    "                            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 1)\n",
    "                            cv2.putText(frame, name_to_display, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 1)\n",
    "\n",
    "            else: # CROWD mode\n",
    "                 for face in faces:\n",
    "                    fa = face['facial_area']\n",
    "                    x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 165, 0), 1)\n",
    "        except Exception as e:\n",
    "            num_faces = 0\n",
    "        \n",
    "        frames += 1; now = time.time()\n",
    "        if now - last_time >= 1.0:\n",
    "            fps = frames / (now - last_time); frames, last_time = 0, now\n",
    "        \n",
    "        info_text = f\"FPS: {fps:.1f} | Faces: {num_faces} | Mode: {SCENARIO}\"\n",
    "        cv2.putText(frame, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        cv2.imshow(WINDOW_NAME, frame)\n",
    "\n",
    "        if capture_and_stop:\n",
    "            print(\"   Auto-stopping stream...\")\n",
    "            time.sleep(2)\n",
    "            break\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "    cap.release(); cv2.destroyAllWindows()\n",
    "    print(\"\\n✓ Stream stopped.\")\n",
    "\n",
    "else:\n",
    "    print(f\"❌ Error: Invalid MODE selected.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\nSCRIPT FINISHED.\\n\" + \"=\"*60)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
=======
"""
Face Recognition System
-----------------------
A comprehensive face detection and recognition system supporting multiple modes:
- IMAGE: Process static images
- VIDEO: Process video files
- LIVE: Real-time webcam processing
Date: October 2025
"""

import os
import time
from typing import List, Tuple, Optional

import cv2
import numpy as np
import tensorflow as tf
from deepface import DeepFace

# Suppress TensorFlow warnings
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'


# Configuration Parameters

# Operation Mode Configuration
MODE = 'LIVE'  # Options: 'IMAGE', 'VIDEO', 'LIVE'
SCENARIO = 'CROWD'  # Options: 'INDIVIDUAL', 'CROWD'

# Path Configuration
LOCAL_PROJECT_FOLDER = 'C:/Users/mswuk/OneDrive/Desktop/NEURALNERWORK/Dataset'
INPUT_FILENAME = 'testvideo1.mp4'
INPUT_FILE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, INPUT_FILENAME)

# Directory Paths
DATABASE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, "database")
CAPTURE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, "captures")
OUTPUT_PATH = os.path.join(LOCAL_PROJECT_FOLDER, "output")
UNKNOWN_FACES_PATH = os.path.join(LOCAL_PROJECT_FOLDER, "unknown_faces")

# Camera Configuration
CAM_ID = 0

# Model Configuration
DETECTOR_FOR_CROWD = 'retinaface'
DETECTOR_FOR_INDIVIDUAL = 'retinaface'
RECOGNITION_MODEL = 'VGG-Face'
DISTANCE_METRIC = 'cosine'
RECOGNITION_THRESHOLD = 0.60

# Visualization Parameters
CROWD_BOX_COLOR = (139, 0, 0)  # Dark blue in BGR format
CROWD_BOX_THICKNESS = 4

# Performance Tuning for LIVE mode
DETECTION_INTERVAL = 5  # Detect faces every N frames
RECOGNITION_INTERVAL = 10  # Recognize faces every N frames


# Initialization Functions

def initialize_directories() -> None:
    """Create required directories if they don't exist."""
    directories = [DATABASE_PATH, CAPTURE_PATH, OUTPUT_PATH, UNKNOWN_FACES_PATH]
    for path in directories:
        if not os.path.exists(path):
            print(f"Creating directory: {path}")
            os.makedirs(path)


def initialize_gpu() -> None:
    """Configure GPU settings for TensorFlow."""
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print(f"TensorFlow detected GPU: {gpus[0].name}\n")
        except Exception as e:
            print(f"GPU setup error: {e}\n")
    else:
        print("WARNING: TensorFlow did not detect a GPU\n")


# Face Recognition Utilities

class FaceDatabase:
    """Manages the face recognition database."""
    
    def __init__(self):
        self.encodings: List[np.ndarray] = []
        self.names: List[str] = []
    
    def load_database(self, database_path: str, model_name: str) -> None:
        """
        Load face encodings from the database directory.
        
        Args:
            database_path: Path to directory containing reference images
            model_name: DeepFace model to use for encoding
        """
        print("Loading face database for recognition...")
        
        db_images = [
            f for f in os.listdir(database_path)
            if f.lower().endswith(('.png', '.jpg', '.jpeg'))
        ]
        
        if not db_images:
            print("WARNING: Database folder is empty. Recognition will not find matches.\n")
            return
        
        for filename in db_images:
            filepath = os.path.join(database_path, filename)
            try:
                embedding_obj = DeepFace.represent(
                    img_path=filepath,
                    model_name=model_name,
                    enforce_detection=False
                )
                
                if embedding_obj and 'embedding' in embedding_obj[0]:
                    self.encodings.append(embedding_obj[0]['embedding'])
                    name = os.path.splitext(filename)[0].replace("_", " ")
                    self.names.append(name)
                    print(f"  Processed: {name}")
            except Exception as e:
                print(f"  Could not process {filename}: {e}")
        
        print(f"Database loaded: {len(self.names)} known faces\n")
    
    def find_best_match(
        self,
        target_embedding: np.ndarray,
        threshold: float
    ) -> Optional[str]:
        """
        Find the best matching face from the database.
        
        Args:
            target_embedding: Face embedding to match
            threshold: Maximum distance for a valid match
            
        Returns:
            Name of matched person or None if no match found
        """
        if not self.encodings:
            return None
        
        distances = []
        for known_embedding in self.encodings:
            # Cosine distance calculation
            distance = 1 - np.dot(target_embedding, known_embedding) / (
                np.linalg.norm(target_embedding) * np.linalg.norm(known_embedding)
            )
            distances.append(distance)
        
        if distances:
            min_idx = np.argmin(distances)
            if distances[min_idx] <= threshold:
                return self.names[min_idx]
        
        return None


def validate_face_region(
    x: int, y: int, w: int, h: int,
    frame_width: int, frame_height: int
) -> Tuple[int, int, int, int, bool]:
    """
    Validate and constrain face region coordinates.
    
    Args:
        x, y, w, h: Face bounding box coordinates
        frame_width, frame_height: Frame dimensions
        
    Returns:
        Tuple of (x, y, w, h, is_valid)
    """
    x = max(0, x)
    y = max(0, y)
    w = min(w, frame_width - x)
    h = min(h, frame_height - y)
    
    is_valid = w > 0 and h > 0
    return x, y, w, h, is_valid


def draw_face_box_with_label(
    frame: np.ndarray,
    x: int, y: int, w: int, h: int,
    label: str,
    color: Tuple[int, int, int],
    with_background: bool = False
) -> None:
    """Draw bounding box and label on frame."""
    cv2.rectangle(frame, (x, y), (x + w, y + h), color, 3)
    
    if with_background:
        text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0]
        cv2.rectangle(frame, (x, y - 35), (x + text_size[0] + 10, y), color, -1)
        cv2.putText(frame, label, (x + 5, y - 10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)
    else:
        cv2.putText(frame, label, (x, y - 15),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)


def save_unknown_face(
    face_roi: np.ndarray,
    unknown_path: str,
    prefix: str,
    counter: int
) -> str:
    """Save unknown face image and return filename."""
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    filename = f"{prefix}_{timestamp}_{counter}.jpg"
    filepath = os.path.join(unknown_path, filename)
    cv2.imwrite(filepath, face_roi)
    return filename


# Image Processing Mode

def process_image_mode(
    input_path: str,
    output_path: str,
    unknown_path: str,
    scenario: str,
    detector: str,
    face_db: FaceDatabase,
    recognition_model: str,
    threshold: float
) -> None:
    """Process a single image file."""
    print(f"\nMODE: IMAGE | SCENARIO: {scenario} | Detector: {detector}")
    print(f"FILE: {os.path.basename(input_path)}\n")
    
    if not os.path.exists(input_path):
        print(f"Error: Image file not found at {input_path}")
        return
    
    try:
        img = cv2.imread(input_path)
        
        if img is None:
            print("Error: Could not read image file")
            return
        
        print("Detecting faces...")
        faces = DeepFace.extract_faces(
            img_path=img,
            detector_backend=detector,
            enforce_detection=False,
            align=False
        )
        
        num_faces = len(faces)
        print(f"Found {num_faces} face(s)\n")
        
        unknown_face_count = 0
        
        if scenario == 'INDIVIDUAL' and num_faces > 0:
            print("Performing face recognition...")
            
            for idx, face in enumerate(faces, 1):
                fa = face['facial_area']
                x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']
                
                x, y, w, h, is_valid = validate_face_region(
                    x, y, w, h, img.shape[1], img.shape[0]
                )
                
                if not is_valid:
                    print(f"  Face {idx}: Invalid dimensions, skipping")
                    continue
                
                face_roi = img[y:y + h, x:x + w]
                
                if face_roi.size == 0:
                    print(f"  Face {idx}: Empty region, skipping")
                    continue
                
                try:
                    face_embedding_obj = DeepFace.represent(
                        img_path=face_roi,
                        model_name=recognition_model,
                        enforce_detection=False
                    )
                    
                    if face_embedding_obj and 'embedding' in face_embedding_obj[0]:
                        identity = face_db.find_best_match(
                            face_embedding_obj[0]['embedding'],
                            threshold
                        )
                        
                        if identity:
                            color = (0, 255, 0)  # Green
                            label = identity
                            print(f"  Face {idx}: Recognized as {identity}")
                        else:
                            color = (0, 0, 255)  # Red
                            label = "Unknown"
                            unknown_face_count += 1
                            
                            filename = save_unknown_face(
                                face_roi, unknown_path, "unknown", unknown_face_count
                            )
                            print(f"  Face {idx}: Unknown - saved as {filename}")
                        
                        draw_face_box_with_label(img, x, y, w, h, label, color)
                
                except Exception as e:
                    print(f"  Face {idx}: Recognition error: {e}")
        
        elif scenario == 'CROWD':
            for face in faces:
                fa = face['facial_area']
                x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']
                cv2.rectangle(img, (x, y), (x + w, y + h),
                            CROWD_BOX_COLOR, CROWD_BOX_THICKNESS)
        
        # Save output
        output_filename = 'output_' + os.path.basename(input_path)
        output_filepath = os.path.join(output_path, output_filename)
        cv2.imwrite(output_filepath, img)
        print(f"\nOutput saved: {output_filepath}")
        
        # Display result
        print("Displaying result. Press any key to close.")
        cv2.imshow('Image Result', img)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    
    except Exception as e:
        print(f"Error during image processing: {e}")


# Video Processing Mode

def process_video_mode(
    input_path: str,
    output_path: str,
    unknown_path: str,
    scenario: str,
    detector: str,
    face_db: FaceDatabase,
    recognition_model: str,
    threshold: float
) -> None:
    """Process a video file."""
    print(f"\nMODE: VIDEO | SCENARIO: {scenario} | Detector: {detector}")
    print(f"FILE: {os.path.basename(input_path)}\n")
    
    if not os.path.exists(input_path):
        print(f"Error: Video file not found at {input_path}")
        return
    
    cap = cv2.VideoCapture(input_path)
    
    if not cap.isOpened():
        print("Error: Could not open video file")
        return
    
    # Get video properties
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    
    if fps <= 0:
        fps = 30
        print("Warning: Invalid FPS detected, using default 30 FPS")
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # Setup output video writer
    output_filename = 'output_' + os.path.splitext(os.path.basename(input_path))[0] + '.mp4'
    output_filepath = os.path.join(output_path, output_filename)
    
    fourcc_options = ['H264', 'mp4v', 'avc1', 'XVID']
    out = None
    
    for codec in fourcc_options:
        try:
            fourcc = cv2.VideoWriter_fourcc(*codec)
            out = cv2.VideoWriter(output_filepath, fourcc, fps, (frame_width, frame_height))
            if out.isOpened():
                print(f"Using codec: {codec}")
                break
        except:
            continue
    
    if out is None or not out.isOpened():
        print("Error: Could not initialize video writer")
        cap.release()
        return
    
    print(f"Video: {frame_width}x{frame_height} @ {fps} FPS")
    print(f"Total frames: {total_frames}\n")
    print("Processing video...")
    
    frame_number = 0
    unknown_face_count = 0
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        frame_number += 1
        
        try:
            faces = DeepFace.extract_faces(
                img_path=frame,
                detector_backend=detector,
                enforce_detection=False,
                align=False
            )
            
            if scenario == 'INDIVIDUAL' and len(faces) > 0:
                for face in faces:
                    fa = face['facial_area']
                    x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']
                    
                    x, y, w, h, is_valid = validate_face_region(
                        x, y, w, h, frame.shape[1], frame.shape[0]
                    )
                    
                    if not is_valid:
                        continue
                    
                    face_roi = frame[y:y + h, x:x + w]
                    
                    if face_roi.size == 0:
                        continue
                    
                    try:
                        face_embedding_obj = DeepFace.represent(
                            img_path=face_roi,
                            model_name=recognition_model,
                            enforce_detection=False
                        )
                        
                        if face_embedding_obj and 'embedding' in face_embedding_obj[0]:
                            identity = face_db.find_best_match(
                                face_embedding_obj[0]['embedding'],
                                threshold
                            )
                            
                            color = (0, 255, 0) if identity else (0, 0, 255)
                            label = identity if identity else "Unknown"
                            
                            if not identity and frame_number % 30 == 0:
                                unknown_face_count += 1
                                save_unknown_face(
                                    face_roi, unknown_path,
                                    "unknown_video", unknown_face_count
                                )
                            
                            draw_face_box_with_label(frame, x, y, w, h, label, color)
                    
                    except Exception as e:
                        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 255), 2)
            
            else:  # CROWD mode
                for face in faces:
                    fa = face['facial_area']
                    x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']
                    cv2.rectangle(frame, (x, y), (x + w, y + h),
                                CROWD_BOX_COLOR, CROWD_BOX_THICKNESS)
            
            out.write(frame)
            
            if frame_number % 30 == 0:
                progress = (frame_number / total_frames) * 100 if total_frames > 0 else 0
                print(f"  Frame {frame_number}/{total_frames} ({progress:.1f}%)")
        
        except Exception as e:
            print(f"  Frame {frame_number}: Error - {e}")
            out.write(frame)
    
    cap.release()
    out.release()
    cv2.destroyAllWindows()
    
    print(f"\nVideo processing complete")
    print(f"Output saved: {output_filepath}")
    if unknown_face_count > 0:
        print(f"Saved {unknown_face_count} unknown faces")


# Live Camera Mode

def process_live_mode(
    cam_id: int,
    capture_path: str,
    unknown_path: str,
    scenario: str,
    detector: str,
    face_db: FaceDatabase,
    recognition_model: str,
    threshold: float
) -> None:
    """Process real-time camera stream."""
    print(f"\nMODE: LIVE | SCENARIO: {scenario} | Detector: {detector}")
    print("Starting real-time camera stream...")
    print("Press 'q' to quit\n")
    
    cap = cv2.VideoCapture(cam_id)
    if not cap.isOpened():
        print(f"Camera failed to open at ID {cam_id}")
        print("Try changing CAM_ID to 1 or 2, or check camera permissions.")
        return
    
    # Configure camera
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    cap.set(cv2.CAP_PROP_FPS, 30)
    
    WINDOW_NAME = "Live Face Recognition (Press 'q' to quit)"
    cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)
    
    # Initialize tracking variables
    last_time = time.time()
    fps_frame_count = 0
    fps = 0
    frame_count = 0
    last_detections = []
    capture_and_stop = False
    unknown_face_count = 0
    recognized_people = set()
    
    print("Camera opened successfully\n")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            print("Failed to read frame")
            break
        
        frame_count += 1
        fps_frame_count += 1
        display_frame = frame.copy()
        
        # Calculate FPS
        current_time = time.time()
        if current_time - last_time >= 1.0:
            fps = fps_frame_count / (current_time - last_time)
            fps_frame_count = 0
            last_time = current_time
        
        # Detect faces periodically
        if frame_count % DETECTION_INTERVAL == 0 or frame_count == 1:
            try:
                faces = DeepFace.extract_faces(
                    img_path=frame,
                    detector_backend=detector,
                    enforce_detection=False,
                    align=False
                )
                last_detections = faces
            except Exception as e:
                print(f"Detection error: {e}")
                last_detections = []
        
        num_faces = len(last_detections)
        
        # Process detected faces
        if scenario == 'INDIVIDUAL' and num_faces > 0:
            for face in last_detections:
                fa = face['facial_area']
                x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']
                
                x, y, w, h, is_valid = validate_face_region(
                    x, y, w, h, frame.shape[1], frame.shape[0]
                )
                
                if not is_valid:
                    continue
                
                # Recognize faces periodically
                if frame_count % RECOGNITION_INTERVAL == 0:
                    try:
                        face_roi = frame[y:y + h, x:x + w]
                        if face_roi.size > 0:
                            face_embedding_obj = DeepFace.represent(
                                img_path=face_roi,
                                model_name=recognition_model,
                                enforce_detection=False
                            )
                            
                            if face_embedding_obj and 'embedding' in face_embedding_obj[0]:
                                identity = face_db.find_best_match(
                                    face_embedding_obj[0]['embedding'],
                                    threshold
                                )
                                
                                if identity:
                                    color = (0, 255, 0)
                                    label = identity
                                    
                                    draw_face_box_with_label(
                                        display_frame, x, y, w, h, label, color,
                                        with_background=True
                                    )
                                    
                                    # Capture once per person
                                    if identity not in recognized_people:
                                        timestamp = time.strftime("%Y%m%d_%H%M%S")
                                        capture_filename = f"capture_{identity.replace(' ', '_')}_{timestamp}.jpg"
                                        capture_filepath = os.path.join(capture_path, capture_filename)
                                        cv2.imwrite(capture_filepath, frame)
                                        recognized_people.add(identity)
                                        print(f"Recognized and Captured: {identity}")
                                        
                                        if not capture_and_stop:
                                            capture_and_stop = True
                                
                                else:
                                    color = (0, 0, 255)
                                    label = "Unknown"
                                    
                                    draw_face_box_with_label(
                                        display_frame, x, y, w, h, label, color
                                    )
                                    
                                    if unknown_face_count < 10 and frame_count % 30 == 0:
                                        unknown_face_count += 1
                                        save_unknown_face(
                                            face_roi, unknown_path,
                                            "unknown_live", unknown_face_count
                                        )
                    except Exception as e:
                        cv2.rectangle(display_frame, (x, y), (x + w, y + h), (255, 255, 0), 3)
                else:
                    cv2.rectangle(display_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
        
        elif scenario == 'CROWD' and num_faces > 0:
            for face in last_detections:
                fa = face['facial_area']
                x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']
                cv2.rectangle(display_frame, (x, y), (x + w, y + h),
                            CROWD_BOX_COLOR, CROWD_BOX_THICKNESS)
        
        # Display information overlay
        info_text = f"FPS: {fps:.1f} | Faces: {num_faces} | Mode: {scenario}"
        cv2.rectangle(display_frame, (10, 10), (600, 60), (0, 0, 0), -1)
        cv2.putText(display_frame, info_text, (20, 45),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)
        
        cv2.imshow(WINDOW_NAME, display_frame)
        
        # Stop conditions
        if capture_and_stop:
            print("\nKnown person detected")
            print("Auto-stopping in 2 seconds...")
            cv2.waitKey(2000)
            break
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            print("\nUser pressed 'q' to quit")
            break
    
    cap.release()
    cv2.destroyAllWindows()
    print("Stream stopped")
    print(f"Recognized: {len(recognized_people)} people")
    print(f"Unknown faces saved: {unknown_face_count}")


# Main Execution

def main():
    """Main execution function."""
    # Initialize environment
    initialize_directories()
    initialize_gpu()
    
    # Initialize face database for INDIVIDUAL mode
    face_database = FaceDatabase()
    if SCENARIO == 'INDIVIDUAL':
        face_database.load_database(DATABASE_PATH, RECOGNITION_MODEL)
    
    # Select detector based on scenario
    detector_backend = (
        DETECTOR_FOR_CROWD if SCENARIO == 'CROWD'
        else DETECTOR_FOR_INDIVIDUAL
    )
    
    # Route to appropriate processing mode
    if MODE == 'IMAGE':
        process_image_mode(
            INPUT_FILE_PATH, OUTPUT_PATH, UNKNOWN_FACES_PATH,
            SCENARIO, detector_backend, face_database,
            RECOGNITION_MODEL, RECOGNITION_THRESHOLD
        )
    
    elif MODE == 'VIDEO':
        process_video_mode(
            INPUT_FILE_PATH, OUTPUT_PATH, UNKNOWN_FACES_PATH,
            SCENARIO, detector_backend, face_database,
            RECOGNITION_MODEL, RECOGNITION_THRESHOLD
        )
    
    elif MODE == 'LIVE':
        process_live_mode(
            CAM_ID, CAPTURE_PATH, UNKNOWN_FACES_PATH,
            SCENARIO, detector_backend, face_database,
            RECOGNITION_MODEL, RECOGNITION_THRESHOLD
        )
    
    else:
        print(f"Invalid MODE: {MODE}")
        print("Valid options: 'IMAGE', 'VIDEO', 'LIVE'")
    
    print("\nScript execution completed")


if __name__ == "__main__":
    main()
>>>>>>> 5e699a5fd70b328f243f47bb7a2d88551278f703
