{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqomNs0lVpwZ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Face Recognition System\n",
        "-----------------------\n",
        "A comprehensive face detection and recognition system supporting multiple modes:\n",
        "- IMAGE: Process static images\n",
        "- VIDEO: Process video files\n",
        "- LIVE: Real-time webcam processing\n",
        "Date: October 2025\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import time\n",
        "from typing import List, Tuple, Optional\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from deepface import DeepFace\n",
        "\n",
        "# Suppress TensorFlow warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "\n",
        "# Configuration Parameters\n",
        "\n",
        "# Operation Mode Configuration\n",
        "MODE = 'LIVE'  # Options: 'IMAGE', 'VIDEO', 'LIVE'\n",
        "SCENARIO = 'CROWD'  # Options: 'INDIVIDUAL', 'CROWD'\n",
        "\n",
        "# Path Configuration\n",
        "LOCAL_PROJECT_FOLDER = 'C:/Users/mswuk/OneDrive/Desktop/NEURALNERWORK/Dataset'\n",
        "INPUT_FILENAME = 'testvideo1.mp4'\n",
        "INPUT_FILE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, INPUT_FILENAME)\n",
        "\n",
        "# Directory Paths\n",
        "DATABASE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, \"database\")\n",
        "CAPTURE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, \"captures\")\n",
        "OUTPUT_PATH = os.path.join(LOCAL_PROJECT_FOLDER, \"output\")\n",
        "UNKNOWN_FACES_PATH = os.path.join(LOCAL_PROJECT_FOLDER, \"unknown_faces\")\n",
        "\n",
        "# Camera Configuration\n",
        "CAM_ID = 0\n",
        "\n",
        "# Model Configuration\n",
        "DETECTOR_FOR_CROWD = 'retinaface'\n",
        "DETECTOR_FOR_INDIVIDUAL = 'retinaface'\n",
        "RECOGNITION_MODEL = 'VGG-Face'\n",
        "DISTANCE_METRIC = 'cosine'\n",
        "RECOGNITION_THRESHOLD = 0.60\n",
        "\n",
        "# Visualization Parameters\n",
        "CROWD_BOX_COLOR = (139, 0, 0)  # Dark blue in BGR format\n",
        "CROWD_BOX_THICKNESS = 4\n",
        "\n",
        "# Performance Tuning for LIVE mode\n",
        "DETECTION_INTERVAL = 5  # Detect faces every N frames\n",
        "RECOGNITION_INTERVAL = 10  # Recognize faces every N frames\n",
        "\n",
        "\n",
        "# Initialization Functions\n",
        "\n",
        "def initialize_directories() -> None:\n",
        "    \"\"\"Create required directories if they don't exist.\"\"\"\n",
        "    directories = [DATABASE_PATH, CAPTURE_PATH, OUTPUT_PATH, UNKNOWN_FACES_PATH]\n",
        "    for path in directories:\n",
        "        if not os.path.exists(path):\n",
        "            print(f\"Creating directory: {path}\")\n",
        "            os.makedirs(path)\n",
        "\n",
        "\n",
        "def initialize_gpu() -> None:\n",
        "    \"\"\"Configure GPU settings for TensorFlow.\"\"\"\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            print(f\"TensorFlow detected GPU: {gpus[0].name}\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"GPU setup error: {e}\\n\")\n",
        "    else:\n",
        "        print(\"WARNING: TensorFlow did not detect a GPU\\n\")\n",
        "\n",
        "\n",
        "# Face Recognition Utilities\n",
        "\n",
        "class FaceDatabase:\n",
        "    \"\"\"Manages the face recognition database.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.encodings: List[np.ndarray] = []\n",
        "        self.names: List[str] = []\n",
        "\n",
        "    def load_database(self, database_path: str, model_name: str) -> None:\n",
        "        \"\"\"\n",
        "        Load face encodings from the database directory.\n",
        "\n",
        "        Args:\n",
        "            database_path: Path to directory containing reference images\n",
        "            model_name: DeepFace model to use for encoding\n",
        "        \"\"\"\n",
        "        print(\"Loading face database for recognition...\")\n",
        "\n",
        "        db_images = [\n",
        "            f for f in os.listdir(database_path)\n",
        "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "        ]\n",
        "\n",
        "        if not db_images:\n",
        "            print(\"WARNING: Database folder is empty. Recognition will not find matches.\\n\")\n",
        "            return\n",
        "\n",
        "        for filename in db_images:\n",
        "            filepath = os.path.join(database_path, filename)\n",
        "            try:\n",
        "                embedding_obj = DeepFace.represent(\n",
        "                    img_path=filepath,\n",
        "                    model_name=model_name,\n",
        "                    enforce_detection=False\n",
        "                )\n",
        "\n",
        "                if embedding_obj and 'embedding' in embedding_obj[0]:\n",
        "                    self.encodings.append(embedding_obj[0]['embedding'])\n",
        "                    name = os.path.splitext(filename)[0].replace(\"_\", \" \")\n",
        "                    self.names.append(name)\n",
        "                    print(f\"  Processed: {name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Could not process {filename}: {e}\")\n",
        "\n",
        "        print(f\"Database loaded: {len(self.names)} known faces\\n\")\n",
        "\n",
        "    def find_best_match(\n",
        "        self,\n",
        "        target_embedding: np.ndarray,\n",
        "        threshold: float\n",
        "    ) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        Find the best matching face from the database.\n",
        "\n",
        "        Args:\n",
        "            target_embedding: Face embedding to match\n",
        "            threshold: Maximum distance for a valid match\n",
        "\n",
        "        Returns:\n",
        "            Name of matched person or None if no match found\n",
        "        \"\"\"\n",
        "        if not self.encodings:\n",
        "            return None\n",
        "\n",
        "        distances = []\n",
        "        for known_embedding in self.encodings:\n",
        "            # Cosine distance calculation\n",
        "            distance = 1 - np.dot(target_embedding, known_embedding) / (\n",
        "                np.linalg.norm(target_embedding) * np.linalg.norm(known_embedding)\n",
        "            )\n",
        "            distances.append(distance)\n",
        "\n",
        "        if distances:\n",
        "            min_idx = np.argmin(distances)\n",
        "            if distances[min_idx] <= threshold:\n",
        "                return self.names[min_idx]\n",
        "\n",
        "        return None\n",
        "\n",
        "\n",
        "def validate_face_region(\n",
        "    x: int, y: int, w: int, h: int,\n",
        "    frame_width: int, frame_height: int\n",
        ") -> Tuple[int, int, int, int, bool]:\n",
        "    \"\"\"\n",
        "    Validate and constrain face region coordinates.\n",
        "\n",
        "    Args:\n",
        "        x, y, w, h: Face bounding box coordinates\n",
        "        frame_width, frame_height: Frame dimensions\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (x, y, w, h, is_valid)\n",
        "    \"\"\"\n",
        "    x = max(0, x)\n",
        "    y = max(0, y)\n",
        "    w = min(w, frame_width - x)\n",
        "    h = min(h, frame_height - y)\n",
        "\n",
        "    is_valid = w > 0 and h > 0\n",
        "    return x, y, w, h, is_valid\n",
        "\n",
        "\n",
        "def draw_face_box_with_label(\n",
        "    frame: np.ndarray,\n",
        "    x: int, y: int, w: int, h: int,\n",
        "    label: str,\n",
        "    color: Tuple[int, int, int],\n",
        "    with_background: bool = False\n",
        ") -> None:\n",
        "    \"\"\"Draw bounding box and label on frame.\"\"\"\n",
        "    cv2.rectangle(frame, (x, y), (x + w, y + h), color, 3)\n",
        "\n",
        "    if with_background:\n",
        "        text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0]\n",
        "        cv2.rectangle(frame, (x, y - 35), (x + text_size[0] + 10, y), color, -1)\n",
        "        cv2.putText(frame, label, (x + 5, y - 10),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
        "    else:\n",
        "        cv2.putText(frame, label, (x, y - 15),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
        "\n",
        "\n",
        "def save_unknown_face(\n",
        "    face_roi: np.ndarray,\n",
        "    unknown_path: str,\n",
        "    prefix: str,\n",
        "    counter: int\n",
        ") -> str:\n",
        "    \"\"\"Save unknown face image and return filename.\"\"\"\n",
        "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"{prefix}_{timestamp}_{counter}.jpg\"\n",
        "    filepath = os.path.join(unknown_path, filename)\n",
        "    cv2.imwrite(filepath, face_roi)\n",
        "    return filename\n",
        "\n",
        "\n",
        "# Image Processing Mode\n",
        "\n",
        "def process_image_mode(\n",
        "    input_path: str,\n",
        "    output_path: str,\n",
        "    unknown_path: str,\n",
        "    scenario: str,\n",
        "    detector: str,\n",
        "    face_db: FaceDatabase,\n",
        "    recognition_model: str,\n",
        "    threshold: float\n",
        ") -> None:\n",
        "    \"\"\"Process a single image file.\"\"\"\n",
        "    print(f\"\\nMODE: IMAGE | SCENARIO: {scenario} | Detector: {detector}\")\n",
        "    print(f\"FILE: {os.path.basename(input_path)}\\n\")\n",
        "\n",
        "    if not os.path.exists(input_path):\n",
        "        print(f\"Error: Image file not found at {input_path}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        img = cv2.imread(input_path)\n",
        "\n",
        "        if img is None:\n",
        "            print(\"Error: Could not read image file\")\n",
        "            return\n",
        "\n",
        "        print(\"Detecting faces...\")\n",
        "        faces = DeepFace.extract_faces(\n",
        "            img_path=img,\n",
        "            detector_backend=detector,\n",
        "            enforce_detection=False,\n",
        "            align=False\n",
        "        )\n",
        "\n",
        "        num_faces = len(faces)\n",
        "        print(f\"Found {num_faces} face(s)\\n\")\n",
        "\n",
        "        unknown_face_count = 0\n",
        "\n",
        "        if scenario == 'INDIVIDUAL' and num_faces > 0:\n",
        "            print(\"Performing face recognition...\")\n",
        "\n",
        "            for idx, face in enumerate(faces, 1):\n",
        "                fa = face['facial_area']\n",
        "                x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']\n",
        "\n",
        "                x, y, w, h, is_valid = validate_face_region(\n",
        "                    x, y, w, h, img.shape[1], img.shape[0]\n",
        "                )\n",
        "\n",
        "                if not is_valid:\n",
        "                    print(f\"  Face {idx}: Invalid dimensions, skipping\")\n",
        "                    continue\n",
        "\n",
        "                face_roi = img[y:y + h, x:x + w]\n",
        "\n",
        "                if face_roi.size == 0:\n",
        "                    print(f\"  Face {idx}: Empty region, skipping\")\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    face_embedding_obj = DeepFace.represent(\n",
        "                        img_path=face_roi,\n",
        "                        model_name=recognition_model,\n",
        "                        enforce_detection=False\n",
        "                    )\n",
        "\n",
        "                    if face_embedding_obj and 'embedding' in face_embedding_obj[0]:\n",
        "                        identity = face_db.find_best_match(\n",
        "                            face_embedding_obj[0]['embedding'],\n",
        "                            threshold\n",
        "                        )\n",
        "\n",
        "                        if identity:\n",
        "                            color = (0, 255, 0)  # Green\n",
        "                            label = identity\n",
        "                            print(f\"  Face {idx}: Recognized as {identity}\")\n",
        "                        else:\n",
        "                            color = (0, 0, 255)  # Red\n",
        "                            label = \"Unknown\"\n",
        "                            unknown_face_count += 1\n",
        "\n",
        "                            filename = save_unknown_face(\n",
        "                                face_roi, unknown_path, \"unknown\", unknown_face_count\n",
        "                            )\n",
        "                            print(f\"  Face {idx}: Unknown - saved as {filename}\")\n",
        "\n",
        "                        draw_face_box_with_label(img, x, y, w, h, label, color)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  Face {idx}: Recognition error: {e}\")\n",
        "\n",
        "        elif scenario == 'CROWD':\n",
        "            for face in faces:\n",
        "                fa = face['facial_area']\n",
        "                x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']\n",
        "                cv2.rectangle(img, (x, y), (x + w, y + h),\n",
        "                            CROWD_BOX_COLOR, CROWD_BOX_THICKNESS)\n",
        "\n",
        "        # Save output\n",
        "        output_filename = 'output_' + os.path.basename(input_path)\n",
        "        output_filepath = os.path.join(output_path, output_filename)\n",
        "        cv2.imwrite(output_filepath, img)\n",
        "        print(f\"\\nOutput saved: {output_filepath}\")\n",
        "\n",
        "        # Display result\n",
        "        print(\"Displaying result. Press any key to close.\")\n",
        "        cv2.imshow('Image Result', img)\n",
        "        cv2.waitKey(0)\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during image processing: {e}\")\n",
        "\n",
        "\n",
        "# Video Processing Mode\n",
        "\n",
        "def process_video_mode(\n",
        "    input_path: str,\n",
        "    output_path: str,\n",
        "    unknown_path: str,\n",
        "    scenario: str,\n",
        "    detector: str,\n",
        "    face_db: FaceDatabase,\n",
        "    recognition_model: str,\n",
        "    threshold: float\n",
        ") -> None:\n",
        "    \"\"\"Process a video file.\"\"\"\n",
        "    print(f\"\\nMODE: VIDEO | SCENARIO: {scenario} | Detector: {detector}\")\n",
        "    print(f\"FILE: {os.path.basename(input_path)}\\n\")\n",
        "\n",
        "    if not os.path.exists(input_path):\n",
        "        print(f\"Error: Video file not found at {input_path}\")\n",
        "        return\n",
        "\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open video file\")\n",
        "        return\n",
        "\n",
        "    # Get video properties\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    if fps <= 0:\n",
        "        fps = 30\n",
        "        print(\"Warning: Invalid FPS detected, using default 30 FPS\")\n",
        "\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Setup output video writer\n",
        "    output_filename = 'output_' + os.path.splitext(os.path.basename(input_path))[0] + '.mp4'\n",
        "    output_filepath = os.path.join(output_path, output_filename)\n",
        "\n",
        "    fourcc_options = ['H264', 'mp4v', 'avc1', 'XVID']\n",
        "    out = None\n",
        "\n",
        "    for codec in fourcc_options:\n",
        "        try:\n",
        "            fourcc = cv2.VideoWriter_fourcc(*codec)\n",
        "            out = cv2.VideoWriter(output_filepath, fourcc, fps, (frame_width, frame_height))\n",
        "            if out.isOpened():\n",
        "                print(f\"Using codec: {codec}\")\n",
        "                break\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if out is None or not out.isOpened():\n",
        "        print(\"Error: Could not initialize video writer\")\n",
        "        cap.release()\n",
        "        return\n",
        "\n",
        "    print(f\"Video: {frame_width}x{frame_height} @ {fps} FPS\")\n",
        "    print(f\"Total frames: {total_frames}\\n\")\n",
        "    print(\"Processing video...\")\n",
        "\n",
        "    frame_number = 0\n",
        "    unknown_face_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_number += 1\n",
        "\n",
        "        try:\n",
        "            faces = DeepFace.extract_faces(\n",
        "                img_path=frame,\n",
        "                detector_backend=detector,\n",
        "                enforce_detection=False,\n",
        "                align=False\n",
        "            )\n",
        "\n",
        "            if scenario == 'INDIVIDUAL' and len(faces) > 0:\n",
        "                for face in faces:\n",
        "                    fa = face['facial_area']\n",
        "                    x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']\n",
        "\n",
        "                    x, y, w, h, is_valid = validate_face_region(\n",
        "                        x, y, w, h, frame.shape[1], frame.shape[0]\n",
        "                    )\n",
        "\n",
        "                    if not is_valid:\n",
        "                        continue\n",
        "\n",
        "                    face_roi = frame[y:y + h, x:x + w]\n",
        "\n",
        "                    if face_roi.size == 0:\n",
        "                        continue\n",
        "\n",
        "                    try:\n",
        "                        face_embedding_obj = DeepFace.represent(\n",
        "                            img_path=face_roi,\n",
        "                            model_name=recognition_model,\n",
        "                            enforce_detection=False\n",
        "                        )\n",
        "\n",
        "                        if face_embedding_obj and 'embedding' in face_embedding_obj[0]:\n",
        "                            identity = face_db.find_best_match(\n",
        "                                face_embedding_obj[0]['embedding'],\n",
        "                                threshold\n",
        "                            )\n",
        "\n",
        "                            color = (0, 255, 0) if identity else (0, 0, 255)\n",
        "                            label = identity if identity else \"Unknown\"\n",
        "\n",
        "                            if not identity and frame_number % 30 == 0:\n",
        "                                unknown_face_count += 1\n",
        "                                save_unknown_face(\n",
        "                                    face_roi, unknown_path,\n",
        "                                    \"unknown_video\", unknown_face_count\n",
        "                                )\n",
        "\n",
        "                            draw_face_box_with_label(frame, x, y, w, h, label, color)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 255), 2)\n",
        "\n",
        "            else:  # CROWD mode\n",
        "                for face in faces:\n",
        "                    fa = face['facial_area']\n",
        "                    x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']\n",
        "                    cv2.rectangle(frame, (x, y), (x + w, y + h),\n",
        "                                CROWD_BOX_COLOR, CROWD_BOX_THICKNESS)\n",
        "\n",
        "            out.write(frame)\n",
        "\n",
        "            if frame_number % 30 == 0:\n",
        "                progress = (frame_number / total_frames) * 100 if total_frames > 0 else 0\n",
        "                print(f\"  Frame {frame_number}/{total_frames} ({progress:.1f}%)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Frame {frame_number}: Error - {e}\")\n",
        "            out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    print(f\"\\nVideo processing complete\")\n",
        "    print(f\"Output saved: {output_filepath}\")\n",
        "    if unknown_face_count > 0:\n",
        "        print(f\"Saved {unknown_face_count} unknown faces\")\n",
        "\n",
        "\n",
        "# Live Camera Mode\n",
        "\n",
        "def process_live_mode(\n",
        "    cam_id: int,\n",
        "    capture_path: str,\n",
        "    unknown_path: str,\n",
        "    scenario: str,\n",
        "    detector: str,\n",
        "    face_db: FaceDatabase,\n",
        "    recognition_model: str,\n",
        "    threshold: float\n",
        ") -> None:\n",
        "    \"\"\"Process real-time camera stream.\"\"\"\n",
        "    print(f\"\\nMODE: LIVE | SCENARIO: {scenario} | Detector: {detector}\")\n",
        "    print(\"Starting real-time camera stream...\")\n",
        "    print(\"Press 'q' to quit\\n\")\n",
        "\n",
        "    cap = cv2.VideoCapture(cam_id)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Camera failed to open at ID {cam_id}\")\n",
        "        print(\"Try changing CAM_ID to 1 or 2, or check camera permissions.\")\n",
        "        return\n",
        "\n",
        "    # Configure camera\n",
        "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
        "    cap.set(cv2.CAP_PROP_FPS, 30)\n",
        "\n",
        "    WINDOW_NAME = \"Live Face Recognition (Press 'q' to quit)\"\n",
        "    cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
        "\n",
        "    # Initialize tracking variables\n",
        "    last_time = time.time()\n",
        "    fps_frame_count = 0\n",
        "    fps = 0\n",
        "    frame_count = 0\n",
        "    last_detections = []\n",
        "    capture_and_stop = False\n",
        "    unknown_face_count = 0\n",
        "    recognized_people = set()\n",
        "\n",
        "    print(\"Camera opened successfully\\n\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Failed to read frame\")\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "        fps_frame_count += 1\n",
        "        display_frame = frame.copy()\n",
        "\n",
        "        # Calculate FPS\n",
        "        current_time = time.time()\n",
        "        if current_time - last_time >= 1.0:\n",
        "            fps = fps_frame_count / (current_time - last_time)\n",
        "            fps_frame_count = 0\n",
        "            last_time = current_time\n",
        "\n",
        "        # Detect faces periodically\n",
        "        if frame_count % DETECTION_INTERVAL == 0 or frame_count == 1:\n",
        "            try:\n",
        "                faces = DeepFace.extract_faces(\n",
        "                    img_path=frame,\n",
        "                    detector_backend=detector,\n",
        "                    enforce_detection=False,\n",
        "                    align=False\n",
        "                )\n",
        "                last_detections = faces\n",
        "            except Exception as e:\n",
        "                print(f\"Detection error: {e}\")\n",
        "                last_detections = []\n",
        "\n",
        "        num_faces = len(last_detections)\n",
        "\n",
        "        # Process detected faces\n",
        "        if scenario == 'INDIVIDUAL' and num_faces > 0:\n",
        "            for face in last_detections:\n",
        "                fa = face['facial_area']\n",
        "                x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']\n",
        "\n",
        "                x, y, w, h, is_valid = validate_face_region(\n",
        "                    x, y, w, h, frame.shape[1], frame.shape[0]\n",
        "                )\n",
        "\n",
        "                if not is_valid:\n",
        "                    continue\n",
        "\n",
        "                # Recognize faces periodically\n",
        "                if frame_count % RECOGNITION_INTERVAL == 0:\n",
        "                    try:\n",
        "                        face_roi = frame[y:y + h, x:x + w]\n",
        "                        if face_roi.size > 0:\n",
        "                            face_embedding_obj = DeepFace.represent(\n",
        "                                img_path=face_roi,\n",
        "                                model_name=recognition_model,\n",
        "                                enforce_detection=False\n",
        "                            )\n",
        "\n",
        "                            if face_embedding_obj and 'embedding' in face_embedding_obj[0]:\n",
        "                                identity = face_db.find_best_match(\n",
        "                                    face_embedding_obj[0]['embedding'],\n",
        "                                    threshold\n",
        "                                )\n",
        "\n",
        "                                if identity:\n",
        "                                    color = (0, 255, 0)\n",
        "                                    label = identity\n",
        "\n",
        "                                    draw_face_box_with_label(\n",
        "                                        display_frame, x, y, w, h, label, color,\n",
        "                                        with_background=True\n",
        "                                    )\n",
        "\n",
        "                                    # Capture once per person\n",
        "                                    if identity not in recognized_people:\n",
        "                                        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "                                        capture_filename = f\"capture_{identity.replace(' ', '_')}_{timestamp}.jpg\"\n",
        "                                        capture_filepath = os.path.join(capture_path, capture_filename)\n",
        "                                        cv2.imwrite(capture_filepath, frame)\n",
        "                                        recognized_people.add(identity)\n",
        "                                        print(f\"Recognized and Captured: {identity}\")\n",
        "\n",
        "                                        if not capture_and_stop:\n",
        "                                            capture_and_stop = True\n",
        "\n",
        "                                else:\n",
        "                                    color = (0, 0, 255)\n",
        "                                    label = \"Unknown\"\n",
        "\n",
        "                                    draw_face_box_with_label(\n",
        "                                        display_frame, x, y, w, h, label, color\n",
        "                                    )\n",
        "\n",
        "                                    if unknown_face_count < 10 and frame_count % 30 == 0:\n",
        "                                        unknown_face_count += 1\n",
        "                                        save_unknown_face(\n",
        "                                            face_roi, unknown_path,\n",
        "                                            \"unknown_live\", unknown_face_count\n",
        "                                        )\n",
        "                    except Exception as e:\n",
        "                        cv2.rectangle(display_frame, (x, y), (x + w, y + h), (255, 255, 0), 3)\n",
        "                else:\n",
        "                    cv2.rectangle(display_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "        elif scenario == 'CROWD' and num_faces > 0:\n",
        "            for face in last_detections:\n",
        "                fa = face['facial_area']\n",
        "                x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']\n",
        "                cv2.rectangle(display_frame, (x, y), (x + w, y + h),\n",
        "                            CROWD_BOX_COLOR, CROWD_BOX_THICKNESS)\n",
        "\n",
        "        # Display information overlay\n",
        "        info_text = f\"FPS: {fps:.1f} | Faces: {num_faces} | Mode: {scenario}\"\n",
        "        cv2.rectangle(display_frame, (10, 10), (600, 60), (0, 0, 0), -1)\n",
        "        cv2.putText(display_frame, info_text, (20, 45),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)\n",
        "\n",
        "        cv2.imshow(WINDOW_NAME, display_frame)\n",
        "\n",
        "        # Stop conditions\n",
        "        if capture_and_stop:\n",
        "            print(\"\\nKnown person detected\")\n",
        "            print(\"Auto-stopping in 2 seconds...\")\n",
        "            cv2.waitKey(2000)\n",
        "            break\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            print(\"\\nUser pressed 'q' to quit\")\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(\"Stream stopped\")\n",
        "    print(f\"Recognized: {len(recognized_people)} people\")\n",
        "    print(f\"Unknown faces saved: {unknown_face_count}\")\n",
        "\n",
        "\n",
        "# Main Execution\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function.\"\"\"\n",
        "    # Initialize environment\n",
        "    initialize_directories()\n",
        "    initialize_gpu()\n",
        "\n",
        "    # Initialize face database for INDIVIDUAL mode\n",
        "    face_database = FaceDatabase()\n",
        "    if SCENARIO == 'INDIVIDUAL':\n",
        "        face_database.load_database(DATABASE_PATH, RECOGNITION_MODEL)\n",
        "\n",
        "    # Select detector based on scenario\n",
        "    detector_backend = (\n",
        "        DETECTOR_FOR_CROWD if SCENARIO == 'CROWD'\n",
        "        else DETECTOR_FOR_INDIVIDUAL\n",
        "    )\n",
        "\n",
        "    # Route to appropriate processing mode\n",
        "    if MODE == 'IMAGE':\n",
        "        process_image_mode(\n",
        "            INPUT_FILE_PATH, OUTPUT_PATH, UNKNOWN_FACES_PATH,\n",
        "            SCENARIO, detector_backend, face_database,\n",
        "            RECOGNITION_MODEL, RECOGNITION_THRESHOLD\n",
        "        )\n",
        "\n",
        "    elif MODE == 'VIDEO':\n",
        "        process_video_mode(\n",
        "            INPUT_FILE_PATH, OUTPUT_PATH, UNKNOWN_FACES_PATH,\n",
        "            SCENARIO, detector_backend, face_database,\n",
        "            RECOGNITION_MODEL, RECOGNITION_THRESHOLD\n",
        "        )\n",
        "\n",
        "    elif MODE == 'LIVE':\n",
        "        process_live_mode(\n",
        "            CAM_ID, CAPTURE_PATH, UNKNOWN_FACES_PATH,\n",
        "            SCENARIO, detector_backend, face_database,\n",
        "            RECOGNITION_MODEL, RECOGNITION_THRESHOLD\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        print(f\"Invalid MODE: {MODE}\")\n",
        "        print(\"Valid options: 'IMAGE', 'VIDEO', 'LIVE'\")\n",
        "\n",
        "    print(\"\\nScript execution completed\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}