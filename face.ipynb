"""
Face Recognition System
-----------------------
A comprehensive face detection and recognition system supporting multiple modes:
- IMAGE: Process static images
- VIDEO: Process video files
- LIVE: Real-time webcam processing
Date: October 2025
"""

import os
import time
from typing import List, Tuple, Optional

import cv2
import numpy as np
import tensorflow as tf
from deepface import DeepFace

# Suppress TensorFlow warnings
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'


# Configuration Parameters

# Operation Mode Configuration
MODE = 'LIVE'  # Options: 'IMAGE', 'VIDEO', 'LIVE'
SCENARIO = 'CROWD'  # Options: 'INDIVIDUAL', 'CROWD'

# Path Configuration
LOCAL_PROJECT_FOLDER = 'C:/Users/mswuk/OneDrive/Desktop/NEURALNERWORK/Dataset'
INPUT_FILENAME = 'testvideo1.mp4'
INPUT_FILE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, INPUT_FILENAME)

# Directory Paths
DATABASE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, "database")
CAPTURE_PATH = os.path.join(LOCAL_PROJECT_FOLDER, "captures")
OUTPUT_PATH = os.path.join(LOCAL_PROJECT_FOLDER, "output")
UNKNOWN_FACES_PATH = os.path.join(LOCAL_PROJECT_FOLDER, "unknown_faces")

# Camera Configuration
CAM_ID = 0

# Model Configuration
DETECTOR_FOR_CROWD = 'retinaface'
DETECTOR_FOR_INDIVIDUAL = 'retinaface'
RECOGNITION_MODEL = 'VGG-Face'
DISTANCE_METRIC = 'cosine'
RECOGNITION_THRESHOLD = 0.60

# Visualization Parameters
CROWD_BOX_COLOR = (139, 0, 0)  # Dark blue in BGR format
CROWD_BOX_THICKNESS = 4

# Performance Tuning for LIVE mode
DETECTION_INTERVAL = 5  # Detect faces every N frames
RECOGNITION_INTERVAL = 10  # Recognize faces every N frames


# Initialization Functions

def initialize_directories() -> None:
    """Create required directories if they don't exist."""
    directories = [DATABASE_PATH, CAPTURE_PATH, OUTPUT_PATH, UNKNOWN_FACES_PATH]
    for path in directories:
        if not os.path.exists(path):
            print(f"Creating directory: {path}")
            os.makedirs(path)


def initialize_gpu() -> None:
    """Configure GPU settings for TensorFlow."""
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print(f"TensorFlow detected GPU: {gpus[0].name}\n")
        except Exception as e:
            print(f"GPU setup error: {e}\n")
    else:
        print("WARNING: TensorFlow did not detect a GPU\n")


# Face Recognition Utilities

class FaceDatabase:
    """Manages the face recognition database."""
    
    def __init__(self):
        self.encodings: List[np.ndarray] = []
        self.names: List[str] = []
    
    def load_database(self, database_path: str, model_name: str) -> None:
        """
        Load face encodings from the database directory.
        
        Args:
            database_path: Path to directory containing reference images
            model_name: DeepFace model to use for encoding
        """
        print("Loading face database for recognition...")
        
        db_images = [
            f for f in os.listdir(database_path)
            if f.lower().endswith(('.png', '.jpg', '.jpeg'))
        ]
        
        if not db_images:
            print("WARNING: Database folder is empty. Recognition will not find matches.\n")
            return
        
        for filename in db_images:
            filepath = os.path.join(database_path, filename)
            try:
                embedding_obj = DeepFace.represent(
                    img_path=filepath,
                    model_name=model_name,
                    enforce_detection=False
                )
                
                if embedding_obj and 'embedding' in embedding_obj[0]:
                    self.encodings.append(embedding_obj[0]['embedding'])
                    name = os.path.splitext(filename)[0].replace("_", " ")
                    self.names.append(name)
                    print(f"  Processed: {name}")
            except Exception as e:
                print(f"  Could not process {filename}: {e}")
        
        print(f"Database loaded: {len(self.names)} known faces\n")
    
    def find_best_match(
        self,
        target_embedding: np.ndarray,
        threshold: float
    ) -> Optional[str]:
        """
        Find the best matching face from the database.
        
        Args:
            target_embedding: Face embedding to match
            threshold: Maximum distance for a valid match
            
        Returns:
            Name of matched person or None if no match found
        """
        if not self.encodings:
            return None
        
        distances = []
        for known_embedding in self.encodings:
            # Cosine distance calculation
            distance = 1 - np.dot(target_embedding, known_embedding) / (
                np.linalg.norm(target_embedding) * np.linalg.norm(known_embedding)
            )
            distances.append(distance)
        
        if distances:
            min_idx = np.argmin(distances)
            if distances[min_idx] <= threshold:
                return self.names[min_idx]
        
        return None


def validate_face_region(
    x: int, y: int, w: int, h: int,
    frame_width: int, frame_height: int
) -> Tuple[int, int, int, int, bool]:
    """
    Validate and constrain face region coordinates.
    
    Args:
        x, y, w, h: Face bounding box coordinates
        frame_width, frame_height: Frame dimensions
        
    Returns:
        Tuple of (x, y, w, h, is_valid)
    """
    x = max(0, x)
    y = max(0, y)
    w = min(w, frame_width - x)
    h = min(h, frame_height - y)
    
    is_valid = w > 0 and h > 0
    return x, y, w, h, is_valid


def draw_face_box_with_label(
    frame: np.ndarray,
    x: int, y: int, w: int, h: int,
    label: str,
    color: Tuple[int, int, int],
    with_background: bool = False
) -> None:
    """Draw bounding box and label on frame."""
    cv2.rectangle(frame, (x, y), (x + w, y + h), color, 3)
    
    if with_background:
        text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0]
        cv2.rectangle(frame, (x, y - 35), (x + text_size[0] + 10, y), color, -1)
        cv2.putText(frame, label, (x + 5, y - 10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)
    else:
        cv2.putText(frame, label, (x, y - 15),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)


def save_unknown_face(
    face_roi: np.ndarray,
    unknown_path: str,
    prefix: str,
    counter: int
) -> str:
    """Save unknown face image and return filename."""
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    filename = f"{prefix}_{timestamp}_{counter}.jpg"
    filepath = os.path.join(unknown_path, filename)
    cv2.imwrite(filepath, face_roi)
    return filename


# Image Processing Mode

def process_image_mode(
    input_path: str,
    output_path: str,
    unknown_path: str,
    scenario: str,
    detector: str,
    face_db: FaceDatabase,
    recognition_model: str,
    threshold: float
) -> None:
    """Process a single image file."""
    print(f"\nMODE: IMAGE | SCENARIO: {scenario} | Detector: {detector}")
    print(f"FILE: {os.path.basename(input_path)}\n")
    
    if not os.path.exists(input_path):
        print(f"Error: Image file not found at {input_path}")
        return
    
    try:
        img = cv2.imread(input_path)
        
        if img is None:
            print("Error: Could not read image file")
            return
        
        print("Detecting faces...")
        faces = DeepFace.extract_faces(
            img_path=img,
            detector_backend=detector,
            enforce_detection=False,
            align=False
        )
        
        num_faces = len(faces)
        print(f"Found {num_faces} face(s)\n")
        
        unknown_face_count = 0
        
        if scenario == 'INDIVIDUAL' and num_faces > 0:
            print("Performing face recognition...")
            
            for idx, face in enumerate(faces, 1):
                fa = face['facial_area']
                x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']
                
                x, y, w, h, is_valid = validate_face_region(
                    x, y, w, h, img.shape[1], img.shape[0]
                )
                
                if not is_valid:
                    print(f"  Face {idx}: Invalid dimensions, skipping")
                    continue
                
                face_roi = img[y:y + h, x:x + w]
                
                if face_roi.size == 0:
                    print(f"  Face {idx}: Empty region, skipping")
                    continue
                
                try:
                    face_embedding_obj = DeepFace.represent(
                        img_path=face_roi,
                        model_name=recognition_model,
                        enforce_detection=False
                    )
                    
                    if face_embedding_obj and 'embedding' in face_embedding_obj[0]:
                        identity = face_db.find_best_match(
                            face_embedding_obj[0]['embedding'],
                            threshold
                        )
                        
                        if identity:
                            color = (0, 255, 0)  # Green
                            label = identity
                            print(f"  Face {idx}: Recognized as {identity}")
                        else:
                            color = (0, 0, 255)  # Red
                            label = "Unknown"
                            unknown_face_count += 1
                            
                            filename = save_unknown_face(
                                face_roi, unknown_path, "unknown", unknown_face_count
                            )
                            print(f"  Face {idx}: Unknown - saved as {filename}")
                        
                        draw_face_box_with_label(img, x, y, w, h, label, color)
                
                except Exception as e:
                    print(f"  Face {idx}: Recognition error: {e}")
        
        elif scenario == 'CROWD':
            for face in faces:
                fa = face['facial_area']
                x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']
                cv2.rectangle(img, (x, y), (x + w, y + h),
                            CROWD_BOX_COLOR, CROWD_BOX_THICKNESS)
        
        # Save output
        output_filename = 'output_' + os.path.basename(input_path)
        output_filepath = os.path.join(output_path, output_filename)
        cv2.imwrite(output_filepath, img)
        print(f"\nOutput saved: {output_filepath}")
        
        # Display result
        print("Displaying result. Press any key to close.")
        cv2.imshow('Image Result', img)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    
    except Exception as e:
        print(f"Error during image processing: {e}")


# Video Processing Mode

def process_video_mode(
    input_path: str,
    output_path: str,
    unknown_path: str,
    scenario: str,
    detector: str,
    face_db: FaceDatabase,
    recognition_model: str,
    threshold: float
) -> None:
    """Process a video file."""
    print(f"\nMODE: VIDEO | SCENARIO: {scenario} | Detector: {detector}")
    print(f"FILE: {os.path.basename(input_path)}\n")
    
    if not os.path.exists(input_path):
        print(f"Error: Video file not found at {input_path}")
        return
    
    cap = cv2.VideoCapture(input_path)
    
    if not cap.isOpened():
        print("Error: Could not open video file")
        return
    
    # Get video properties
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    
    if fps <= 0:
        fps = 30
        print("Warning: Invalid FPS detected, using default 30 FPS")
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # Setup output video writer
    output_filename = 'output_' + os.path.splitext(os.path.basename(input_path))[0] + '.mp4'
    output_filepath = os.path.join(output_path, output_filename)
    
    fourcc_options = ['H264', 'mp4v', 'avc1', 'XVID']
    out = None
    
    for codec in fourcc_options:
        try:
            fourcc = cv2.VideoWriter_fourcc(*codec)
            out = cv2.VideoWriter(output_filepath, fourcc, fps, (frame_width, frame_height))
            if out.isOpened():
                print(f"Using codec: {codec}")
                break
        except:
            continue
    
    if out is None or not out.isOpened():
        print("Error: Could not initialize video writer")
        cap.release()
        return
    
    print(f"Video: {frame_width}x{frame_height} @ {fps} FPS")
    print(f"Total frames: {total_frames}\n")
    print("Processing video...")
    
    frame_number = 0
    unknown_face_count = 0
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        frame_number += 1
        
        try:
            faces = DeepFace.extract_faces(
                img_path=frame,
                detector_backend=detector,
                enforce_detection=False,
                align=False
            )
            
            if scenario == 'INDIVIDUAL' and len(faces) > 0:
                for face in faces:
                    fa = face['facial_area']
                    x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']
                    
                    x, y, w, h, is_valid = validate_face_region(
                        x, y, w, h, frame.shape[1], frame.shape[0]
                    )
                    
                    if not is_valid:
                        continue
                    
                    face_roi = frame[y:y + h, x:x + w]
                    
                    if face_roi.size == 0:
                        continue
                    
                    try:
                        face_embedding_obj = DeepFace.represent(
                            img_path=face_roi,
                            model_name=recognition_model,
                            enforce_detection=False
                        )
                        
                        if face_embedding_obj and 'embedding' in face_embedding_obj[0]:
                            identity = face_db.find_best_match(
                                face_embedding_obj[0]['embedding'],
                                threshold
                            )
                            
                            color = (0, 255, 0) if identity else (0, 0, 255)
                            label = identity if identity else "Unknown"
                            
                            if not identity and frame_number % 30 == 0:
                                unknown_face_count += 1
                                save_unknown_face(
                                    face_roi, unknown_path,
                                    "unknown_video", unknown_face_count
                                )
                            
                            draw_face_box_with_label(frame, x, y, w, h, label, color)
                    
                    except Exception as e:
                        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 255), 2)
            
            else:  # CROWD mode
                for face in faces:
                    fa = face['facial_area']
                    x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']
                    cv2.rectangle(frame, (x, y), (x + w, y + h),
                                CROWD_BOX_COLOR, CROWD_BOX_THICKNESS)
            
            out.write(frame)
            
            if frame_number % 30 == 0:
                progress = (frame_number / total_frames) * 100 if total_frames > 0 else 0
                print(f"  Frame {frame_number}/{total_frames} ({progress:.1f}%)")
        
        except Exception as e:
            print(f"  Frame {frame_number}: Error - {e}")
            out.write(frame)
    
    cap.release()
    out.release()
    cv2.destroyAllWindows()
    
    print(f"\nVideo processing complete")
    print(f"Output saved: {output_filepath}")
    if unknown_face_count > 0:
        print(f"Saved {unknown_face_count} unknown faces")


# Live Camera Mode

def process_live_mode(
    cam_id: int,
    capture_path: str,
    unknown_path: str,
    scenario: str,
    detector: str,
    face_db: FaceDatabase,
    recognition_model: str,
    threshold: float
) -> None:
    """Process real-time camera stream."""
    print(f"\nMODE: LIVE | SCENARIO: {scenario} | Detector: {detector}")
    print("Starting real-time camera stream...")
    print("Press 'q' to quit\n")
    
    cap = cv2.VideoCapture(cam_id)
    if not cap.isOpened():
        print(f"Camera failed to open at ID {cam_id}")
        print("Try changing CAM_ID to 1 or 2, or check camera permissions.")
        return
    
    # Configure camera
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    cap.set(cv2.CAP_PROP_FPS, 30)
    
    WINDOW_NAME = "Live Face Recognition (Press 'q' to quit)"
    cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)
    
    # Initialize tracking variables
    last_time = time.time()
    fps_frame_count = 0
    fps = 0
    frame_count = 0
    last_detections = []
    capture_and_stop = False
    unknown_face_count = 0
    recognized_people = set()
    
    print("Camera opened successfully\n")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            print("Failed to read frame")
            break
        
        frame_count += 1
        fps_frame_count += 1
        display_frame = frame.copy()
        
        # Calculate FPS
        current_time = time.time()
        if current_time - last_time >= 1.0:
            fps = fps_frame_count / (current_time - last_time)
            fps_frame_count = 0
            last_time = current_time
        
        # Detect faces periodically
        if frame_count % DETECTION_INTERVAL == 0 or frame_count == 1:
            try:
                faces = DeepFace.extract_faces(
                    img_path=frame,
                    detector_backend=detector,
                    enforce_detection=False,
                    align=False
                )
                last_detections = faces
            except Exception as e:
                print(f"Detection error: {e}")
                last_detections = []
        
        num_faces = len(last_detections)
        
        # Process detected faces
        if scenario == 'INDIVIDUAL' and num_faces > 0:
            for face in last_detections:
                fa = face['facial_area']
                x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']
                
                x, y, w, h, is_valid = validate_face_region(
                    x, y, w, h, frame.shape[1], frame.shape[0]
                )
                
                if not is_valid:
                    continue
                
                # Recognize faces periodically
                if frame_count % RECOGNITION_INTERVAL == 0:
                    try:
                        face_roi = frame[y:y + h, x:x + w]
                        if face_roi.size > 0:
                            face_embedding_obj = DeepFace.represent(
                                img_path=face_roi,
                                model_name=recognition_model,
                                enforce_detection=False
                            )
                            
                            if face_embedding_obj and 'embedding' in face_embedding_obj[0]:
                                identity = face_db.find_best_match(
                                    face_embedding_obj[0]['embedding'],
                                    threshold
                                )
                                
                                if identity:
                                    color = (0, 255, 0)
                                    label = identity
                                    
                                    draw_face_box_with_label(
                                        display_frame, x, y, w, h, label, color,
                                        with_background=True
                                    )
                                    
                                    # Capture once per person
                                    if identity not in recognized_people:
                                        timestamp = time.strftime("%Y%m%d_%H%M%S")
                                        capture_filename = f"capture_{identity.replace(' ', '_')}_{timestamp}.jpg"
                                        capture_filepath = os.path.join(capture_path, capture_filename)
                                        cv2.imwrite(capture_filepath, frame)
                                        recognized_people.add(identity)
                                        print(f"Recognized and Captured: {identity}")
                                        
                                        if not capture_and_stop:
                                            capture_and_stop = True
                                
                                else:
                                    color = (0, 0, 255)
                                    label = "Unknown"
                                    
                                    draw_face_box_with_label(
                                        display_frame, x, y, w, h, label, color
                                    )
                                    
                                    if unknown_face_count < 10 and frame_count % 30 == 0:
                                        unknown_face_count += 1
                                        save_unknown_face(
                                            face_roi, unknown_path,
                                            "unknown_live", unknown_face_count
                                        )
                    except Exception as e:
                        cv2.rectangle(display_frame, (x, y), (x + w, y + h), (255, 255, 0), 3)
                else:
                    cv2.rectangle(display_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
        
        elif scenario == 'CROWD' and num_faces > 0:
            for face in last_detections:
                fa = face['facial_area']
                x, y, w, h = fa['x'], fa['y'], fa['w'], fa['h']
                cv2.rectangle(display_frame, (x, y), (x + w, y + h),
                            CROWD_BOX_COLOR, CROWD_BOX_THICKNESS)
        
        # Display information overlay
        info_text = f"FPS: {fps:.1f} | Faces: {num_faces} | Mode: {scenario}"
        cv2.rectangle(display_frame, (10, 10), (600, 60), (0, 0, 0), -1)
        cv2.putText(display_frame, info_text, (20, 45),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)
        
        cv2.imshow(WINDOW_NAME, display_frame)
        
        # Stop conditions
        if capture_and_stop:
            print("\nKnown person detected")
            print("Auto-stopping in 2 seconds...")
            cv2.waitKey(2000)
            break
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            print("\nUser pressed 'q' to quit")
            break
    
    cap.release()
    cv2.destroyAllWindows()
    print("Stream stopped")
    print(f"Recognized: {len(recognized_people)} people")
    print(f"Unknown faces saved: {unknown_face_count}")


# Main Execution

def main():
    """Main execution function."""
    # Initialize environment
    initialize_directories()
    initialize_gpu()
    
    # Initialize face database for INDIVIDUAL mode
    face_database = FaceDatabase()
    if SCENARIO == 'INDIVIDUAL':
        face_database.load_database(DATABASE_PATH, RECOGNITION_MODEL)
    
    # Select detector based on scenario
    detector_backend = (
        DETECTOR_FOR_CROWD if SCENARIO == 'CROWD'
        else DETECTOR_FOR_INDIVIDUAL
    )
    
    # Route to appropriate processing mode
    if MODE == 'IMAGE':
        process_image_mode(
            INPUT_FILE_PATH, OUTPUT_PATH, UNKNOWN_FACES_PATH,
            SCENARIO, detector_backend, face_database,
            RECOGNITION_MODEL, RECOGNITION_THRESHOLD
        )
    
    elif MODE == 'VIDEO':
        process_video_mode(
            INPUT_FILE_PATH, OUTPUT_PATH, UNKNOWN_FACES_PATH,
            SCENARIO, detector_backend, face_database,
            RECOGNITION_MODEL, RECOGNITION_THRESHOLD
        )
    
    elif MODE == 'LIVE':
        process_live_mode(
            CAM_ID, CAPTURE_PATH, UNKNOWN_FACES_PATH,
            SCENARIO, detector_backend, face_database,
            RECOGNITION_MODEL, RECOGNITION_THRESHOLD
        )
    
    else:
        print(f"Invalid MODE: {MODE}")
        print("Valid options: 'IMAGE', 'VIDEO', 'LIVE'")
    
    print("\nScript execution completed")


if __name__ == "__main__":
    main()
